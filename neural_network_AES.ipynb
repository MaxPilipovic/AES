{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46207d26-c1fb-4ef0-ab8c-6f6761ff133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\independent_study\\lib\\site-packages\\PIL\\Image.py:121: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: \"9.2.0\"\n",
      "Pillow version: 9.2.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n",
      "E:\\Program Files\\Anaconda3\\envs\\independent_study\\lib\\site-packages\\PIL\\Image.py:121: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: \"9.2.0\"\n",
      "Pillow version: 9.2.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing #scaling\n",
    "from keras.layers import Dropout            #for random dropout\n",
    "from keras.optimizers import Adam   #for adam optimizer\n",
    "from keras import regularizers      #for l2 regularization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62e30fb-0def-40c9-82c5-735119c0659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_dataframe(fileName):\n",
    "    data = np.fromfile(fileName, dtype='uint32')\n",
    "    plain = []\n",
    "    cipher = []\n",
    "    for i in range(len(data)):\n",
    "        if i % 2 == 0:\n",
    "            plain.append(data[i])\n",
    "        else:\n",
    "            cipher.append(data[i])\n",
    "    df_plain = pd.DataFrame(plain)\n",
    "    df_plain.columns = ['plaintext']\n",
    "    df_cipher = pd.DataFrame(cipher)\n",
    "    df_cipher.columns = ['ciphertext']\n",
    "    df_combo = pd.concat([df_plain, df_cipher], axis = 1)\n",
    "    key = fileName.strip('.bin')\n",
    "    key = ''.join(key.split())\n",
    "    df_combo[\"key\"] = key\n",
    "    return df_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a8f836-05a6-46b2-b8b1-b273aba63468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           plaintext  ciphertext                       key\n",
      "0          825241648   808464688  011001100111010101101100\n",
      "1          808464689   825307184  011001100111010101101100\n",
      "2          825241648   825241649  011001100111010101101100\n",
      "3          825307184   808464433  011001100111010101101100\n",
      "4         1666607958  2017547341  011001100111010101101100\n",
      "...              ...         ...                       ...\n",
      "10485755  2017547341  1482053208  011011010110010101100111\n",
      "10485756  2000770125  2001028173  011011010110010101100111\n",
      "10485757  1465009752  2017547341  011011010110010101100111\n",
      "10485758  2017809485  1465271896  011011010110010101100111\n",
      "10485759  1095058509  1094795585  011011010110010101100111\n",
      "\n",
      "[20971520 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Bin file is generated from the 2x2 or 3x3 AES implementation. Currently only combines two files,\n",
    "    but more can be used. Key is the file name in binary.\n",
    "'''\n",
    "df1 = bin_to_dataframe('01100110 01110101 01101100.bin') # key = ful\n",
    "df2 = bin_to_dataframe('01101101 01100101 01100111.bin') # key = meg\n",
    "combined_data = pd.concat([df1, df2])\n",
    "print(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d480dcc7-a8d4-4063-8285-3a701c31ed74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 825241648  808464688]\n",
      " [ 808464689  825307184]\n",
      " [ 825241648  825241649]\n",
      " ...\n",
      " [1465009752 2017547341]\n",
      " [2017809485 1465271896]\n",
      " [1095058509 1094795585]]\n",
      "['key']\n",
      "['plaintext', 'ciphertext']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14680064, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['011001100111010101101100', '011011010110010101100111']\n",
    "combined_data['key'] = combined_data['key'].replace( {'011001100111010101101100': 0, '011011010110010101100111': 1} )\n",
    "target_column = ['key']\n",
    "predictors = combined_data.columns.values.tolist()\n",
    "predictors.remove('key')\n",
    "\n",
    "print(combined_data[predictors].values)\n",
    "print(target_column)\n",
    "print(predictors)\n",
    "\n",
    "X = combined_data[predictors].values\n",
    "y = combined_data[target_column].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "count_classes = y_test.shape[1]\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f151161-9343-496d-8536-8359bc871fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_dim=2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20)\n",
    "    pred_train= model.predict(X_train)\n",
    "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    "\n",
    "    pred_test= model.predict(X_test)\n",
    "    scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1])) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37683501-3e13-4bd0-8139-e0318a3ca2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = len(predictors)\n",
    "input_shape = (n_cols, )\n",
    "# Creates a model given an activation and learning rate\n",
    "def create_model(learning_rate = 0.01, activation = 'relu'):\n",
    "  \n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    opt = Adam(lr=learning_rate)\n",
    "  \n",
    "    # Create your binary classification model  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, \n",
    "                    activation = activation,\n",
    "                    input_shape = input_shape,\n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dense(50,\n",
    "                    activation = activation, \n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dense(20,\n",
    "                    activation = activation, \n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dense(2, activation = activation))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = \"mean_absolute_error\",\n",
    "                  metrics=['mse', \"mape\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff206c-ed4e-4e89-b6c3-bb75fc56d224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 194s 659us/step - loss: 0.4285 - mse: 0.4019 - mape: 403967680.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 203s 689us/step - loss: 0.4247 - mse: 0.3940 - mape: 396583776.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 218s 739us/step - loss: 0.4245 - mse: 0.3920 - mape: 394448704.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 374s 1ms/step - loss: 0.4243 - mse: 0.3916 - mape: 394002592.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 483s 2ms/step - loss: 0.4243 - mse: 0.3910 - mape: 393161408.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 497s 2ms/step - loss: 0.4242 - mse: 0.3908 - mape: 392712256.0000\n",
      "32768/32768 [==============================] - 35s 1ms/step - loss: 0.9918 - mse: 0.9803 - mape: 989869440.0000\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 444s 2ms/step - loss: 0.3425 - mse: 0.2859 - mape: 305292864.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 211s 716us/step - loss: 0.3389 - mse: 0.2842 - mape: 304584544.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 198s 672us/step - loss: 0.3387 - mse: 0.2846 - mape: 305372832.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 197s 666us/step - loss: 0.3384 - mse: 0.2841 - mape: 304995456.0000 - loss: 0.3384 - mse: 0.2841 - mape: 3049\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 195s 661us/step - loss: 0.3379 - mse: 0.2840 - mape: 304973120.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 194s 659us/step - loss: 0.3376 - mse: 0.2837 - mape: 304791168.0000\n",
      "32768/32768 [==============================] - 14s 427us/step - loss: 0.5943 - mse: 0.5774 - mape: 592663680.0000s - loss: 0.5944 - mse: 0.577\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 194s 659us/step - loss: 0.3683 - mse: 0.3107 - mape: 324163168.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 194s 658us/step - loss: 0.3638 - mse: 0.3080 - mape: 322870944.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 194s 659us/step - loss: 0.3634 - mse: 0.3082 - mape: 323537664.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 199s 675us/step - loss: 0.3631 - mse: 0.3085 - mape: 324192864.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 193s 655us/step - loss: 0.3630 - mse: 0.3088 - mape: 324873504.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 189s 642us/step - loss: 0.3629 - mse: 0.3087 - mape: 324135328.0000\n",
      "    1/32768 [..............................] - ETA: 0s - loss: 0.5764 - mse: 0.5606 - mape: 574684928.0000WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "32768/32768 [==============================] - 14s 416us/step - loss: 0.5974 - mse: 0.5819 - mape: 595678208.0000\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 194s 658us/step - loss: 0.3556 - mse: 0.2963 - mape: 312337248.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 194s 658us/step - loss: 0.3514 - mse: 0.2943 - mape: 312413472.0000 - loss: 0.3514 - mse: 0.2943 - \n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 196s 665us/step - loss: 0.3509 - mse: 0.2949 - mape: 313505440.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 196s 665us/step - loss: 0.3506 - mse: 0.2950 - mape: 313799712.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 195s 662us/step - loss: 0.3506 - mse: 0.2950 - mape: 313738944.0000 - loss: 0.3506 - mse: 0.2950 - mape: 313741312.00\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 196s 664us/step - loss: 0.3505 - mse: 0.2947 - mape: 313596384.0000\n",
      "32768/32768 [==============================] - 14s 422us/step - loss: 0.6008 - mse: 0.5763 - mape: 599140544.0000s - loss: 0.6008 - mse: 0.5763 - mape: 59913900\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 207s 703us/step - loss: 0.3553 - mse: 0.2960 - mape: 308559744.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 205s 694us/step - loss: 0.3512 - mse: 0.2940 - mape: 307386624.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 211s 715us/step - loss: 0.3510 - mse: 0.2944 - mape: 307938336.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 209s 710us/step - loss: 0.3508 - mse: 0.2946 - mape: 308505472.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 211s 715us/step - loss: 0.3506 - mse: 0.2944 - mape: 308312672.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 203s 688us/step - loss: 0.3503 - mse: 0.2944 - mape: 308370176.0000\n",
      "32768/32768 [==============================] - 15s 445us/step - loss: 0.6192 - mse: 0.5764 - mape: 617596224.0000\n",
      "Epoch 1/6\n",
      "     1/294912 [..............................] - ETA: 4:52 - loss: 0.6624 - mse: 0.6664 - mape: 419708256.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "294912/294912 [==============================] - 201s 681us/step - loss: 0.3743 - mse: 0.2540 - mape: 95645848.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 228s 773us/step - loss: 0.3720 - mse: 0.2527 - mape: 92414936.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 468s 2ms/step - loss: 0.3718 - mse: 0.2526 - mape: 92149496.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 484s 2ms/step - loss: 0.3717 - mse: 0.2526 - mape: 92008272.0000 5s - loss: 0.3717 - ms - ETA: 0s - loss: 0.3717 - mse: 0.2526 - mape: \n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 481s 2ms/step - loss: 0.3715 - mse: 0.2523 - mape: 92188856.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 264s 896us/step - loss: 0.3716 - mse: 0.2526 - mape: 91974072.0000\n",
      "32768/32768 [==============================] - 15s 468us/step - loss: 0.5285 - mse: 0.3924 - mape: 52.67681s - los\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 229s 777us/step - loss: 0.3822 - mse: 0.2606 - mape: 94995352.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 282s 957us/step - loss: 0.3800 - mse: 0.2596 - mape: 91948696.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 205s 696us/step - loss: 0.3798 - mse: 0.2593 - mape: 91745752.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 206s 698us/step - loss: 0.3797 - mse: 0.2591 - mape: 91803104.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 206s 699us/step - loss: 0.3796 - mse: 0.2590 - mape: 91829728.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 212s 718us/step - loss: 0.3796 - mse: 0.2591 - mape: 91702944.0000\n",
      "32768/32768 [==============================] - 15s 463us/step - loss: 0.5364 - mse: 0.3976 - mape: 53.4714\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 208s 706us/step - loss: 0.4348 - mse: 0.3338 - mape: 66164600.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 208s 706us/step - loss: 0.4339 - mse: 0.3310 - mape: 66446776.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 208s 706us/step - loss: 0.4339 - mse: 0.3308 - mape: 66549432.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 208s 706us/step - loss: 0.4339 - mse: 0.3310 - mape: 66437296.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 208s 707us/step - loss: 0.4338 - mse: 0.3310 - mape: 66393436.0000s - loss: 0.4338 - mse: 0\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 209s 707us/step - loss: 0.4338 - mse: 0.3309 - mape: 66449876.0000\n",
      "32768/32768 [==============================] - 15s 465us/step - loss: 0.7401 - mse: 0.6023 - mape: 73.8339\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 207s 703us/step - loss: 0.3777 - mse: 0.2526 - mape: 110696168.0000\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 208s 705us/step - loss: 0.3758 - mse: 0.2517 - mape: 109082880.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 202s 683us/step - loss: 0.3755 - mse: 0.2516 - mape: 109053888.0000\n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 197s 667us/step - loss: 0.3754 - mse: 0.2516 - mape: 109192992.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 197s 667us/step - loss: 0.3752 - mse: 0.2517 - mape: 109288976.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 197s 667us/step - loss: 0.3753 - mse: 0.2517 - mape: 109650784.0000\n",
      "32768/32768 [==============================] - 14s 438us/step - loss: 0.5379 - mse: 0.4086 - mape: 53.6153\n",
      "Epoch 1/6\n",
      "294912/294912 [==============================] - 194s 659us/step - loss: 0.4355 - mse: 0.3404 - mape: 62118172.0000s - loss: 0.4355 - mse: 0.3404 - mape: 62118092.00\n",
      "Epoch 2/6\n",
      "294912/294912 [==============================] - 189s 641us/step - loss: 0.4344 - mse: 0.3378 - mape: 61918648.0000\n",
      "Epoch 3/6\n",
      "294912/294912 [==============================] - 189s 640us/step - loss: 0.4343 - mse: 0.3379 - mape: 61773292.0000s - loss: 0.4344 - \n",
      "Epoch 4/6\n",
      "294912/294912 [==============================] - 187s 636us/step - loss: 0.4343 - mse: 0.3380 - mape: 61660336.0000\n",
      "Epoch 5/6\n",
      "294912/294912 [==============================] - 188s 637us/step - loss: 0.4343 - mse: 0.3380 - mape: 61679020.0000\n",
      "Epoch 6/6\n",
      "294912/294912 [==============================] - 188s 637us/step - loss: 0.4343 - mse: 0.3379 - mape: 61724652.0000\n",
      "32768/32768 [==============================] - 14s 417us/step - loss: 0.7679 - mse: 0.6490 - mape: 76.6274\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 314s 533us/step - loss: 0.3812 - mse: 0.3297 - mape: 337827712.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 315s 534us/step - loss: 0.3781 - mse: 0.3299 - mape: 340284000.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 314s 533us/step - loss: 0.3776 - mse: 0.3307 - mape: 341679680.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 315s 534us/step - loss: 0.3774 - mse: 0.3307 - mape: 342086400.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 314s 533us/step - loss: 0.3774 - mse: 0.3313 - mape: 343222432.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 315s 534us/step - loss: 0.3774 - mse: 0.3311 - mape: 342450880.0000\n",
      "65536/65536 [==============================] - 27s 414us/step - loss: 0.7880 - mse: 0.7684 - mape: 785713536.0000\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 321s 545us/step - loss: 0.3957 - mse: 0.3631 - mape: 375056064.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 326s 552us/step - loss: 0.3938 - mse: 0.3622 - mape: 374919712.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 325s 551us/step - loss: 0.3935 - mse: 0.3617 - mape: 374424672.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 322s 545us/step - loss: 0.3934 - mse: 0.3612 - mape: 373707104.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 322s 546us/step - loss: 0.3933 - mse: 0.3608 - mape: 373274464.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 322s 545us/step - loss: 0.3931 - mse: 0.3608 - mape: 373368352.0000\n",
      "65536/65536 [==============================] - 27s 419us/step - loss: 0.7929 - mse: 0.7770 - mape: 791761728.0000\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 322s 546us/step - loss: 0.3573 - mse: 0.2900 - mape: 299806720.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 322s 546us/step - loss: 0.3538 - mse: 0.2875 - mape: 298364608.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 321s 544us/step - loss: 0.3537 - mse: 0.2885 - mape: 300375712.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 322s 545us/step - loss: 0.3534 - mse: 0.2880 - mape: 299187552.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 320s 543us/step - loss: 0.3533 - mse: 0.2875 - mape: 298011872.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 322s 546us/step - loss: 0.3531 - mse: 0.2875 - mape: 298183040.0000\n",
      "65536/65536 [==============================] - 27s 419us/step - loss: 0.6101 - mse: 0.5765 - mape: 608605568.0000\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 321s 545us/step - loss: 0.3898 - mse: 0.3572 - mape: 372388896.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 321s 545us/step - loss: 0.3879 - mse: 0.3565 - mape: 372688192.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 322s 546us/step - loss: 0.3876 - mse: 0.3568 - mape: 373157056.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 322s 546us/step - loss: 0.3875 - mse: 0.3567 - mape: 373353088.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 323s 548us/step - loss: 0.3874 - mse: 0.3570 - mape: 373691136.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 323s 547us/step - loss: 0.3873 - mse: 0.3571 - mape: 373908704.0000\n",
      "65536/65536 [==============================] - 28s 425us/step - loss: 0.7975 - mse: 0.7760 - mape: 796422912.0000\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 324s 550us/step - loss: 0.3682 - mse: 0.3124 - mape: 322901152.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 324s 550us/step - loss: 0.3630 - mse: 0.3088 - mape: 322119232.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 324s 549us/step - loss: 0.3625 - mse: 0.3090 - mape: 322642144.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 324s 550us/step - loss: 0.3622 - mse: 0.3088 - mape: 322550528.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 325s 551us/step - loss: 0.3620 - mse: 0.3087 - mape: 322562624.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.3618 - mse: 0.3092 - mape: 323414240.0000\n",
      "65536/65536 [==============================] - 28s 429us/step - loss: 0.7108 - mse: 0.6620 - mape: 709152704.0000\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 324s 550us/step - loss: 0.4358 - mse: 0.3300 - mape: 70237856.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 325s 551us/step - loss: 0.4352 - mse: 0.3282 - mape: 69860768.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.4351 - mse: 0.3281 - mape: 69899384.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.4351 - mse: 0.3282 - mape: 69858728.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 328s 557us/step - loss: 0.4351 - mse: 0.3281 - mape: 69924696.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.4351 - mse: 0.3280 - mape: 70029608.0000\n",
      "65536/65536 [==============================] - 28s 429us/step - loss: 0.7055 - mse: 0.5459 - mape: 70.3624\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 324s 549us/step - loss: 0.3910 - mse: 0.2672 - mape: 97856528.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 326s 552us/step - loss: 0.3896 - mse: 0.2661 - mape: 96573816.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 326s 552us/step - loss: 0.3895 - mse: 0.2661 - mape: 96643608.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 327s 554us/step - loss: 0.3893 - mse: 0.2660 - mape: 96584376.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 329s 557us/step - loss: 0.3892 - mse: 0.2660 - mape: 96587552.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 328s 557us/step - loss: 0.3893 - mse: 0.2661 - mape: 96743096.0000\n",
      "65536/65536 [==============================] - 29s 448us/step - loss: 0.5779 - mse: 0.4362 - mape: 57.623015s - loss: 0.5779 - ETA: 11s - loss\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 324s 549us/step - loss: 0.3802 - mse: 0.2580 - mape: 102012048.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 324s 550us/step - loss: 0.3783 - mse: 0.2567 - mape: 99646296.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 324s 550us/step - loss: 0.3783 - mse: 0.2567 - mape: 99490544.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.3781 - mse: 0.2565 - mape: 99487264.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 326s 552us/step - loss: 0.3782 - mse: 0.2566 - mape: 99483912.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 326s 552us/step - loss: 0.3781 - mse: 0.2565 - mape: 99462472.0000\n",
      "65536/65536 [==============================] - 29s 442us/step - loss: 0.5412 - mse: 0.4156 - mape: 53.95053s - loss: 0.5412 - m - ET\n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 324s 549us/step - loss: 0.4107 - mse: 0.2922 - mape: 86529672.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 324s 549us/step - loss: 0.4099 - mse: 0.2918 - mape: 85424560.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 326s 552us/step - loss: 0.4098 - mse: 0.2919 - mape: 85180416.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 325s 551us/step - loss: 0.4097 - mse: 0.2918 - mape: 85167440.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 325s 551us/step - loss: 0.4097 - mse: 0.2917 - mape: 85197672.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 325s 551us/step - loss: 0.4096 - mse: 0.2919 - mape: 85015304.0000\n",
      "65536/65536 [==============================] - 29s 446us/step - loss: 0.7298 - mse: 0.6123 - mape: 72.826113 - ETA: 11s - loss:  - ETA: 10s - loss: 0.7299 - mse: 0.6123 - - ETA: 9s - loss: 0.7299 - m - ETA: 8s - loss: 0.7299 - mse: 0.6123 - ma - ETA: 7s - loss: 0.7299 - mse: 0.6123 - mape: 72. - ETA: 7s - \n",
      "Epoch 1/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.3905 - mse: 0.2735 - mape: 90662472.0000\n",
      "Epoch 2/6\n",
      "589824/589824 [==============================] - 326s 553us/step - loss: 0.3889 - mse: 0.2725 - mape: 88224464.0000\n",
      "Epoch 3/6\n",
      "589824/589824 [==============================] - 327s 554us/step - loss: 0.3887 - mse: 0.2723 - mape: 88077944.0000\n",
      "Epoch 4/6\n",
      "589824/589824 [==============================] - 327s 555us/step - loss: 0.3887 - mse: 0.2723 - mape: 88008536.0000\n",
      "Epoch 5/6\n",
      "589824/589824 [==============================] - 328s 556us/step - loss: 0.3886 - mse: 0.2722 - mape: 87919296.0000\n",
      "Epoch 6/6\n",
      "589824/589824 [==============================] - 328s 557us/step - loss: 0.3885 - mse: 0.2721 - mape: 87831248.0000\n",
      "65536/65536 [==============================] - 29s 442us/step - loss: 0.5532 - mse: 0.4226 - mape: 55.1511\n",
      "Epoch 1/12\n",
      "1179648/1179648 [==============================] - 596s 505us/step - loss: 0.4446 - mse: 0.4444 - mape: 444156512.0000\n",
      "Epoch 2/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4445 - mse: 0.4444 - mape: 444168800.0000\n",
      "Epoch 3/12\n",
      "1179648/1179648 [==============================] - 603s 511us/step - loss: 0.4445 - mse: 0.4444 - mape: 444155968.0000\n",
      "Epoch 4/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4445 - mse: 0.4444 - mape: 444162144.0000\n",
      "Epoch 5/12\n",
      "1179648/1179648 [==============================] - 600s 508us/step - loss: 0.4445 - mse: 0.4444 - mape: 444157760.0000\n",
      "Epoch 6/12\n",
      "1179648/1179648 [==============================] - 600s 509us/step - loss: 0.4445 - mse: 0.4444 - mape: 444151264.0000\n",
      "Epoch 7/12\n",
      "1179648/1179648 [==============================] - 598s 507us/step - loss: 0.4445 - mse: 0.4444 - mape: 444165280.0000\n",
      "Epoch 8/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4445 - mse: 0.4444 - mape: 444165248.0000\n",
      "Epoch 9/12\n",
      "1179648/1179648 [==============================] - 600s 508us/step - loss: 0.4445 - mse: 0.4444 - mape: 444164000.0000\n",
      "Epoch 10/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4445 - mse: 0.4444 - mape: 444168352.0000\n",
      "Epoch 11/12\n",
      "1179648/1179648 [==============================] - 635s 539us/step - loss: 0.4445 - mse: 0.4444 - mape: 444164480.0000\n",
      "Epoch 12/12\n",
      "1179648/1179648 [==============================] - 649s 550us/step - loss: 0.4445 - mse: 0.4444 - mape: 444155008.0000\n",
      "131072/131072 [==============================] - 59s 452us/step - loss: 1.0004 - mse: 1.0000 - mape: 998779136.0000\n",
      "Epoch 1/12\n",
      "1179648/1179648 [==============================] - 640s 542us/step - loss: 0.4446 - mse: 0.4444 - mape: 444159136.0000\n",
      "Epoch 2/12\n",
      "1179648/1179648 [==============================] - 626s 530us/step - loss: 0.4445 - mse: 0.4444 - mape: 444159616.0000\n",
      "Epoch 3/12\n",
      "1179648/1179648 [==============================] - 614s 520us/step - loss: 0.4445 - mse: 0.4444 - mape: 444167552.0000\n",
      "Epoch 4/12\n",
      "1179648/1179648 [==============================] - 613s 519us/step - loss: 0.4445 - mse: 0.4444 - mape: 444161920.0000 - loss: 0.4445 - mse: 0.4444 - ma - ETA: 1s - loss: 0.4445 - mse: 0.4 - ETA: 0s - loss: 0.4445 - mse: 0.4444 - ma\n",
      "Epoch 5/12\n",
      "1179648/1179648 [==============================] - 612s 519us/step - loss: 0.4445 - mse: 0.4444 - mape: 444162176.0000\n",
      "Epoch 6/12\n",
      "1179648/1179648 [==============================] - 614s 520us/step - loss: 0.4445 - mse: 0.4444 - mape: 444157824.0000\n",
      "Epoch 7/12\n",
      "1179648/1179648 [==============================] - 614s 521us/step - loss: 0.4445 - mse: 0.4444 - mape: 444163104.0000\n",
      "Epoch 8/12\n",
      "1179648/1179648 [==============================] - 591s 501us/step - loss: 0.4445 - mse: 0.4444 - mape: 444174400.0000\n",
      "Epoch 9/12\n",
      "1179648/1179648 [==============================] - 910s 772us/step - loss: 0.4445 - mse: 0.4444 - mape: 444159392.0000\n",
      "Epoch 11/12\n",
      "1179648/1179648 [==============================] - 843s 715us/step - loss: 0.4445 - mse: 0.4444 - mape: 444174016.0000\n",
      "Epoch 12/12\n",
      "1179648/1179648 [==============================] - 832s 705us/step - loss: 0.4445 - mse: 0.4444 - mape: 444168672.0000\n",
      "131072/131072 [==============================] - 69s 524us/step - loss: 1.0004 - mse: 1.0000 - mape: 998779136.0000\n",
      "Epoch 1/12\n",
      "1179648/1179648 [==============================] - 867s 735us/step - loss: 0.4446 - mse: 0.4444 - mape: 444163168.0000\n",
      "Epoch 2/12\n",
      "1179648/1179648 [==============================] - 1476s 1ms/step - loss: 0.4445 - mse: 0.4444 - mape: 444170304.0000\n",
      "Epoch 11/12\n",
      "1179648/1179648 [==============================] - 979s 830us/step - loss: 0.4446 - mse: 0.4444 - mape: 444160704.0000\n",
      "Epoch 2/12\n",
      "1179648/1179648 [==============================] - 907s 768us/step - loss: 0.4445 - mse: 0.4444 - mape: 444169824.0000\n",
      "Epoch 3/12\n",
      "1179648/1179648 [==============================] - 918s 779us/step - loss: 0.4445 - mse: 0.4444 - mape: 444166176.0000\n",
      "Epoch 8/12\n",
      "1179648/1179648 [==============================] - 1098s 930us/step - loss: 0.4445 - mse: 0.4444 - mape: 444161504.0000\n",
      "Epoch 11/12\n",
      "1179648/1179648 [==============================] - 643s 545us/step - loss: 0.4445 - mse: 0.4444 - mape: 444160128.0000\n",
      "Epoch 12/12\n",
      "1179648/1179648 [==============================] - 804s 682us/step - loss: 0.3905 - mse: 0.2598 - mape: 138690496.0000\n",
      "Epoch 7/12\n",
      "1179648/1179648 [==============================] - 1566s 1ms/step - loss: 0.3874 - mse: 0.2587 - mape: 135524672.0000\n",
      "Epoch 10/12\n",
      "1179648/1179648 [==============================] - 1215s 1ms/step - loss: 0.3868 - mse: 0.2580 - mape: 134485696.0000\n",
      "Epoch 12/12\n",
      "1179648/1179648 [==============================] - 727s 616us/step - loss: 0.3863 - mse: 0.2576 - mape: 133750312.0000\n",
      "131072/131072 [==============================] - 58s 443us/step - loss: 0.4251 - mse: 0.2390 - mape: 42.3442\n",
      "1179648/1179648 [==============================] - 1298s 1ms/step - loss: 0.3873 - mse: 0.2593 - mape: 130429840.0000\n",
      "Epoch 7/12\n",
      "1179648/1179648 [==============================] - 1484s 1ms/step - loss: 0.3855 - mse: 0.2580 - mape: 127994880.0000\n",
      "Epoch 10/12\n",
      "1179648/1179648 [==============================] - 732s 620us/step - loss: 0.3852 - mse: 0.2577 - mape: 127969376.0000\n",
      "Epoch 11/12\n",
      "1179648/1179648 [==============================] - 1105s 937us/step - loss: 0.3912 - mse: 0.2613 - mape: 142255376.0000- loss: 0.3912 - mse: 0.2613 - mape: 14225624\n",
      "Epoch 3/12\n",
      "1179648/1179648 [==============================] - 1178s 999us/step - loss: 0.3877 - mse: 0.2595 - mape: 138485776.0000\n",
      "Epoch 4/12\n",
      "1179648/1179648 [==============================] - 1093s 927us/step - loss: 0.3866 - mse: 0.2592 - mape: 137400400.0000\n",
      "Epoch 5/12\n",
      "1179648/1179648 [==============================] - 652s 552us/step - loss: 0.3856 - mse: 0.2586 - mape: 136389312.0000 - loss: 0.3856 - mse: 0.2586 - mape: \n",
      "Epoch 6/12\n",
      "1179648/1179648 [==============================] - 620s 526us/step - loss: 0.3847 - mse: 0.2580 - mape: 135323760.0000\n",
      "Epoch 7/12\n",
      "1179648/1179648 [==============================] - 603s 511us/step - loss: 0.3846 - mse: 0.2577 - mape: 134406928.0000\n",
      "Epoch 8/12\n",
      "1179648/1179648 [==============================] - 606s 513us/step - loss: 0.3845 - mse: 0.2579 - mape: 135661728.0000\n",
      "Epoch 9/12\n",
      "1179648/1179648 [==============================] - 607s 515us/step - loss: 0.3846 - mse: 0.2581 - mape: 135633504.0000\n",
      "Epoch 10/12\n",
      "1179648/1179648 [==============================] - 607s 515us/step - loss: 0.3841 - mse: 0.2577 - mape: 134751824.0000\n",
      "Epoch 11/12\n",
      "1179648/1179648 [==============================] - 608s 515us/step - loss: 0.3842 - mse: 0.2578 - mape: 135946720.0000\n",
      "Epoch 12/12\n",
      "1179648/1179648 [==============================] - 607s 515us/step - loss: 0.3839 - mse: 0.2575 - mape: 134659264.0000\n",
      "131072/131072 [==============================] - 58s 446us/step - loss: 0.4531 - mse: 0.2911 - mape: 45.1466 - ETA: 12s - loss: 0.4531 - ETA: 11s - loss: 0.4531 - mse: 0. - ETA: 11 -  - ETA: 4s - loss: 0.\n",
      "Epoch 1/12\n",
      "1179648/1179648 [==============================] - 593s 503us/step - loss: 0.4227 - mse: 0.2781 - mape: 168107776.0000\n",
      "Epoch 2/12\n",
      "1179648/1179648 [==============================] - 596s 505us/step - loss: 0.4150 - mse: 0.2741 - mape: 158137888.0000\n",
      "Epoch 3/12\n",
      "1179648/1179648 [==============================] - 599s 507us/step - loss: 0.4116 - mse: 0.2714 - mape: 150863088.0000\n",
      "Epoch 4/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4110 - mse: 0.2717 - mape: 150804368.0000\n",
      "Epoch 5/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4096 - mse: 0.2716 - mape: 149078208.0000\n",
      "Epoch 6/12\n",
      "1179648/1179648 [==============================] - 599s 508us/step - loss: 0.4086 - mse: 0.2717 - mape: 148234048.0000\n",
      "Epoch 7/12\n",
      "1179648/1179648 [==============================] - 602s 510us/step - loss: 0.4082 - mse: 0.2717 - mape: 147571984.0000\n",
      "Epoch 8/12\n",
      "1179648/1179648 [==============================] - 599s 507us/step - loss: 0.4078 - mse: 0.2716 - mape: 146482144.0000\n",
      "Epoch 9/12\n",
      "1179648/1179648 [==============================] - 669s 567us/step - loss: 25017415680.0000 - mse: 12747374854144.0000 - mape: 19534148796416.0000\n",
      "Epoch 2/9\n",
      "1179648/1179648 [==============================] - 653s 554us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5392\n",
      "Epoch 3/9\n",
      "1179648/1179648 [==============================] - 655s 555us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5400s - loss: 0.55 - ETA: 3s - lo - ETA: 1s - loss: 0.5556 - mse: \n",
      "Epoch 4/9\n",
      "1179648/1179648 [==============================] - 629s 533us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5389\n",
      "Epoch 5/9\n",
      "1179648/1179648 [==============================] - 584s 495us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5374\n",
      "Epoch 6/9\n",
      "1179648/1179648 [==============================] - 585s 496us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5385\n",
      "Epoch 7/9\n",
      "1179648/1179648 [==============================] - 585s 496us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5375\n",
      "Epoch 8/9\n",
      "1179648/1179648 [==============================] - 600s 508us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5386\n",
      "Epoch 5/9\n",
      "1179648/1179648 [==============================] - 592s 502us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5384\n",
      "Epoch 8/9\n",
      "1179648/1179648 [==============================] - 592s 501us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5397\n",
      "Epoch 9/9\n",
      "1179648/1179648 [==============================] - 593s 502us/step - loss: 0.5556 - mse: 0.5556 - mape: 55.5383\n",
      "131072/131072 [==============================] - 59s 453us/step - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000e+00 57s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000e - ETA: 57s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000e+ - ETA: 57s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.000 - ETA: 57s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000 - ETA: 57s - loss: 0.0000 - ETA: 51s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.000 - ETA: 50s - loss - ETA: 48s - loss: 0.0000e+00 - mse: 0.0000e+00 - - ETA: 47s - loss: 0.0000e+00 - mse: 0.0000e+00 - ma - ETA: 46s - loss:  - ETA: 44s - loss: 0.0000e+00 - mse: 0.0000e+00 -  - ETA: 43s - loss: 0.0000e+00 - mse: 0.00 - ETA: 39s - loss: 0.0000e+00  - ETA: 37s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000e+0 - ETA: 37s - loss: 0.0000e+00 - mse: 0.0000e+00  - ETA: 36s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.000 - ETA: 36s - loss: 0.0000e+00 - mse: 0.00 - ETA: 34s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000e+0 - ETA: 34s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000e+ - ETA: 34s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0 - ETA: 34s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000 - ETA: 34s - loss: 0.0000e+00 - mse:  - ETA: 32s - loss: 0.0000e+00 - mse - ETA: 30s - loss: 0.0000e+00 - mse: 0.000 - ETA: 29s - loss: 0.0000e+00 - mse: 0.00 - ETA: 28s - loss: 0.0000e+00 - mse: 0.0000e+ - ETA: 27s - loss: 0.0000e+00 - mse: 0. - ETA: 26s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000 - ETA: 25s - loss: 0.0000e+00 - mse: 0.0000e+00  - ETA: 25s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0000 - ETA: 24s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape:  - ETA: 24s - loss: 0.0000e+00 -  - ETA: 22s - loss: 0.0000e+00 - mse: 0.0000e+00 - m - ETA: 21s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.00 - ETA: 21s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: - ETA: 20s - loss: 0.0000e+00 - mse: 0.0000e+00 - mape: 0.0\n",
      "Epoch 1/9\n",
      "      1/1179648 [..............................] - ETA: 0s - loss: 92924654125056.0000 - mse: 134674386102779904.0000 - mape: 17756948506083328.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1179648/1179648 [==============================] - 595s 505us/step - loss: 42392465408.0000 - mse: 16047021228032.0000 - mape: 26129184325632.0000\n",
      "Epoch 2/9\n",
      "1179648/1179648 [==============================] - 585s 495us/step - loss: 25122179072.0000 - mse: 4136061370368.0000 - mape: 12436649279488.0000\n",
      "Epoch 2/9\n",
      "1179648/1179648 [==============================] - 639s 541us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4265\n",
      "Epoch 9/9\n",
      "1179648/1179648 [==============================] - 618s 524us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4266\n",
      "131072/131072 [==============================] - 58s 444us/step - loss: 1.0000 - mse: 1.0000 - mape: 100.0000 54s - loss: 1.0000 - mse: 1.0000 - mape: 100 - ETA:  - ETA: 53s - loss: 1. - ETA: 51s - loss: 1.0000 - mse: 1.0000 - mape:  - ETA: 50s - ETA: 36s - loss: 1.0000 - mse: 1.0000 - mape: 100. - ETA: 36s - loss:  - ETA: 34s - loss: 1.0000 - mse: 1.0000 - mape: 10 - E - ETA: 25s - loss: 1.0000 - mse: 1.0000 -  - ETA: 2 - ETA: 16s - loss: 1.0000  - ETA: 15 - ETA: 12s - loss: 1.0000 - m - E - E - ETA: 5s - loss: 1.0000 - mse: - E - ETA: 3s - loss: 1.0000 - mse: 1.0 - ETA: 2s - loss: 1.0000 - ms - ETA: 2s - loss: 1.0\n",
      "Epoch 1/9\n",
      "1179648/1179648 [==============================] - 615s 522us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4258\n",
      "Epoch 5/9\n",
      "1179648/1179648 [==============================] - 620s 526us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4251s - loss: 0.4445 - ms\n",
      "Epoch 6/9\n",
      "1179648/1179648 [==============================] - 647s 548us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4278\n",
      "131072/131072 [==============================] - 60s 455us/step - loss: 1.0000 - mse: 1.0000 - mape: 100.0000\n",
      "Epoch 1/9\n",
      "1179648/1179648 [==============================] - 636s 539us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4274\n",
      "Epoch 3/9\n",
      "1179648/1179648 [==============================] - 653s 553us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4263\n",
      "Epoch 5/9\n",
      "1179648/1179648 [==============================] - 651s 552us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4268\n",
      "1179648/1179648 [==============================] - 632s 535us/step - loss: 41407893504.0000 - mse: 71321992036352.0000 - mape: 86571055316992.0000\n",
      "Epoch 2/9\n",
      "1179648/1179648 [==============================] - 628s 532us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4264\n",
      "Epoch 4/9\n",
      "1179648/1179648 [==============================] - 625s 530us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4261\n",
      "Epoch 7/9\n",
      "1179648/1179648 [==============================] - 626s 531us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4264\n",
      "Epoch 5/9\n",
      "1179648/1179648 [==============================] - 626s 531us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4260\n",
      "Epoch 6/9\n",
      "1179648/1179648 [==============================] - 627s 531us/step - loss: 0.4444 - mse: 0.4444 - mape: 44.4262\n",
      "131072/131072 [==============================] - 58s 446us/step - loss: 1.0000 - mse: 1.0000 - mape: 100.0000 22s - loss: 1.0000 - mse: 1.0000 - mape: 100. - ETA: 21s - loss: 1.0000 - mse:  - ETA: 20s - loss: 1.0000 - mse: 1.0000 - mape - ETA: 20s - loss: 1.0000 - mse: 1.0000 - mape: 100. - ETA: 20s - loss: 1.0000 - mse: 1.0000 - map - ETA: 19s - loss: - ETA: - ETA: 9s - loss: 1.0000 - mse: 1.0000 - ma - ETA: 7s - loss: 1.0000 - mse: 1.0000 - mape - ETA: 7s - loss: 1.0000 - mse: 1.0000 - mape: 100.00 - ETA: 7s - loss: 1.0000 - mse: 1.0000 - mape: 100.00 - ETA: 7s - loss: 1.0000 - mse: 1.0000 - ma - - ETA: 2s - loss: 1.0000 - mse: 1.0000 -  - ETA: 2s - loss: 1.0000 - mse: 1.0 - ETA: 2s - loss: 1.0000 - mse: 1.000 - ETA: 0s - loss: 1.0000 - mse: 1.0000 - mape: 10\n",
      "Epoch 1/6\n",
      "1179648/1179648 [==============================] - 644s 546us/step - loss: 0.3881 - mse: 0.3356 - mape: 342871680.0000\n",
      "131072/131072 [==============================] - 60s 458us/step - loss: 0.7129 - mse: 0.6240 - mape: 711702592.0000\n",
      "Epoch 1/6\n",
      "1179648/1179648 [==============================] - 652s 553us/step - loss: 0.3995 - mse: 0.3715 - mape: 381925920.0000\n",
      "Epoch 5/6\n",
      "131072/131072 [==============================] - 59s 450us/step - loss: 0.8086 - mse: 0.7828 - mape: 805427776.0000s - loss: 0.8086 - mse: 0.7 - ETA: 1s - l\n",
      "Epoch 1/6\n",
      "131072/131072 [==============================] - 60s 456us/step - loss: 0.7880 - mse: 0.7609 - mape: 785984320.0000\n",
      "Epoch 1/6\n",
      "1179648/1179648 [==============================] - 711s 602us/step - loss: 0.3834 - mse: 0.3386 - mape: 350060864.0000\n",
      "1179648/1179648 [==============================] - 620s 525us/step - loss: 0.3613 - mse: 0.2457 - mape: 91502752.0000s - loss: 0.3613 - mse: 0.2457 - mape: 9150388\n",
      "Epoch 5/6\n",
      "1179648/1179648 [==============================] - 622s 527us/step - loss: 0.3612 - mse: 0.2456 - mape: 91398688.0000s - loss: 0.3612 -\n",
      "Epoch 6/6\n",
      "1179648/1179648 [==============================] - 621s 526us/step - loss: 0.3613 - mse: 0.2457 - mape: 91402480.0000\n",
      "1179648/1179648 [==============================] - 630s 534us/step - loss: 0.4180 - mse: 0.2981 - mape: 115796544.0000\n",
      "Epoch 2/6\n",
      " 799663/1179648 [===================>..........] - ETA: 3:21 - loss: 0.4111 - mse: 0.2931 - mape: 109788400.00"
     ]
    }
   ],
   "source": [
    "# Create a KerasClassifier object\n",
    "model = KerasRegressor(build_fn = create_model,\n",
    "                       verbose = 1)\n",
    "# Define the hyperparameter space\n",
    "params = {'activation': [\"relu\", \"tanh\"],\n",
    "          'batch_size': [16, 32, 64], \n",
    "          'epochs': [6, 9, 12],\n",
    "          'learning_rate': [0.01, 0.001, 0.0001]}\n",
    "# Create a randomize search cv object \n",
    "random_search = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params,\n",
    "                                   cv = KFold(10))\n",
    "random_search_results = random_search.fit(combined_data[predictors].values, combined_data[target_column].values)\n",
    "print(\"Best Score: \",\n",
    "      random_search_results.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40d4ca-1a3d-4990-bce3-8708f96c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Current values used (learning rate, activation function, epochs, etc.) are default\n",
    "    values, should be changed after random_search_results reports the best parameters.\n",
    "'''\n",
    "\n",
    "n_cols = len(predictors)\n",
    "input_shape = (n_cols, )\n",
    "# Creates a model given an activation and learning rate\n",
    "def create_model(learning_rate = 0.01, activation = 'relu'):\n",
    "  \n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    opt = Adam(lr=learning_rate)\n",
    "  \n",
    "    # Create your binary classification model  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, \n",
    "                    activation = activation,\n",
    "                    input_shape = input_shape,\n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dense(50,\n",
    "                    activation = activation, \n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dense(20,\n",
    "                    activation = activation, \n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dense(2, activation = activation))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = \"mean_absolute_error\",\n",
    "                  metrics=['mse', \"mape\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684805c-ca64-4393-b82b-e89dd28c8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Current values used (epochs, batch size etc.) are default\n",
    "    values, should be changed after random_search_results reports the best parameters.\n",
    "    CV, the cross validation value, can be changed too.\n",
    "'''\n",
    "\n",
    "# Create a KerasClassifier object\n",
    "model = KerasRegressor(build_fn = create_model,\n",
    "                       epochs = 6\n",
    "                       batch_size = 16\n",
    "                       verbose = 1)\n",
    "# Calculate the accuracy score for each fold\n",
    "kfolds = cross_val_score(model,\n",
    "                         predictors,\n",
    "                         target_column,\n",
    "                         cv = 10)\n",
    "# Print the mean accuracy\n",
    "print('The mean accuracy was:', kfolds.mean())\n",
    "# Print the accuracy standard deviation\n",
    "print('With a standard deviation of:', kfolds.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
